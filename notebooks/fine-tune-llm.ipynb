{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojZrEy9GuV4C",
    "outputId": "e4ddb0e3-4f77-4476-dcc7-206f5ed5c9b9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /venv/main/lib/python3.10/site-packages (25.0.1)\n",
      "Requirement already satisfied: mlflow in /venv/main/lib/python3.10/site-packages (2.21.3)\n",
      "Requirement already satisfied: transformers in /venv/main/lib/python3.10/site-packages (4.51.1)\n",
      "Requirement already satisfied: datasets in /venv/main/lib/python3.10/site-packages (3.5.0)\n",
      "Requirement already satisfied: boto3 in /venv/main/lib/python3.10/site-packages (1.37.30)\n",
      "Requirement already satisfied: torch in /venv/main/lib/python3.10/site-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: tensorflow in /venv/main/lib/python3.10/site-packages (2.19.0)\n",
      "Requirement already satisfied: huggingface_hub in /venv/main/lib/python3.10/site-packages (0.30.2)\n",
      "Requirement already satisfied: evaluate in /venv/main/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: tqdm in /venv/main/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: tf-keras in /venv/main/lib/python3.10/site-packages (2.19.0)\n",
      "Requirement already satisfied: peft in /venv/main/lib/python3.10/site-packages (0.15.1)\n",
      "Requirement already satisfied: mlflow-skinny==2.21.3 in /venv/main/lib/python3.10/site-packages (from mlflow) (2.21.3)\n",
      "Requirement already satisfied: Flask<4 in /venv/main/lib/python3.10/site-packages (from mlflow) (3.1.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /venv/main/lib/python3.10/site-packages (from mlflow) (3.1.4)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /venv/main/lib/python3.10/site-packages (from mlflow) (1.15.2)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /venv/main/lib/python3.10/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /venv/main/lib/python3.10/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in /venv/main/lib/python3.10/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /venv/main/lib/python3.10/site-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: matplotlib<4 in /venv/main/lib/python3.10/site-packages (from mlflow) (3.10.1)\n",
      "Requirement already satisfied: numpy<3 in /venv/main/lib/python3.10/site-packages (from mlflow) (2.1.2)\n",
      "Requirement already satisfied: pandas<3 in /venv/main/lib/python3.10/site-packages (from mlflow) (2.2.3)\n",
      "Requirement already satisfied: pyarrow<20,>=4.0.0 in /venv/main/lib/python3.10/site-packages (from mlflow) (19.0.1)\n",
      "Requirement already satisfied: scikit-learn<2 in /venv/main/lib/python3.10/site-packages (from mlflow) (1.6.1)\n",
      "Requirement already satisfied: scipy<2 in /venv/main/lib/python3.10/site-packages (from mlflow) (1.15.2)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /venv/main/lib/python3.10/site-packages (from mlflow) (2.0.40)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /venv/main/lib/python3.10/site-packages (from mlflow-skinny==2.21.3->mlflow) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /venv/main/lib/python3.10/site-packages (from mlflow-skinny==2.21.3->mlflow) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle<4 in /venv/main/lib/python3.10/site-packages (from mlflow-skinny==2.21.3->mlflow) (3.1.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /venv/main/lib/python3.10/site-packages (from mlflow-skinny==2.21.3->mlflow) (0.49.0)\n",
      "Requirement already satisfied: fastapi<1 in /venv/main/lib/python3.10/site-packages (from mlflow-skinny==2.21.3->mlflow) (0.115.12)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /venv/main/lib/python3.10/site-packages (from mlflow-skinny==2.21.3->mlflow) (3.1.44)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /venv/main/lib/python3.10/site-packages (from mlflow-skinny==2.21.3->mlflow) (8.6.1)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /venv/main/lib/python3.10/site-packages (from mlflow-skinny==2.21.3->mlflow) (1.31.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /venv/main/lib/python3.10/site-packages (from mlflow-skinny==2.21.3->mlflow) (1.31.1)\n",
      "Requirement already satisfied: packaging<25 in /venv/main/lib/python3.10/site-packages (from mlflow-skinny==2.21.3->mlflow) (24.2)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /venv/main/lib/python3.10/site-packages (from mlflow-skinny==2.21.3->mlflow) (5.29.4)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in /venv/main/lib/python3.10/site-packages (from mlflow-skinny==2.21.3->mlflow) (2.11.3)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /venv/main/lib/python3.10/site-packages (from mlflow-skinny==2.21.3->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /venv/main/lib/python3.10/site-packages (from mlflow-skinny==2.21.3->mlflow) (2.32.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /venv/main/lib/python3.10/site-packages (from mlflow-skinny==2.21.3->mlflow) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /venv/main/lib/python3.10/site-packages (from mlflow-skinny==2.21.3->mlflow) (4.12.2)\n",
      "Requirement already satisfied: uvicorn<1 in /venv/main/lib/python3.10/site-packages (from mlflow-skinny==2.21.3->mlflow) (0.34.0)\n",
      "Requirement already satisfied: filelock in /venv/main/lib/python3.10/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /venv/main/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /venv/main/lib/python3.10/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /venv/main/lib/python3.10/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /venv/main/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /venv/main/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /venv/main/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /venv/main/lib/python3.10/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in /venv/main/lib/python3.10/site-packages (from datasets) (3.11.16)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.30 in /venv/main/lib/python3.10/site-packages (from boto3) (1.37.30)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /venv/main/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /venv/main/lib/python3.10/site-packages (from boto3) (0.11.4)\n",
      "Requirement already satisfied: networkx in /venv/main/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /venv/main/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /venv/main/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /venv/main/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /venv/main/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /venv/main/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /venv/main/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /venv/main/lib/python3.10/site-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /venv/main/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /venv/main/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /venv/main/lib/python3.10/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /venv/main/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /venv/main/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /venv/main/lib/python3.10/site-packages (from tensorflow) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /venv/main/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /venv/main/lib/python3.10/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /venv/main/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /venv/main/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /venv/main/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /venv/main/lib/python3.10/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: setuptools in /venv/main/lib/python3.10/site-packages (from tensorflow) (59.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /venv/main/lib/python3.10/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /venv/main/lib/python3.10/site-packages (from tensorflow) (3.0.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /venv/main/lib/python3.10/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /venv/main/lib/python3.10/site-packages (from tensorflow) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /venv/main/lib/python3.10/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /venv/main/lib/python3.10/site-packages (from tensorflow) (3.9.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /venv/main/lib/python3.10/site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /venv/main/lib/python3.10/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /venv/main/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: psutil in /venv/main/lib/python3.10/site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /venv/main/lib/python3.10/site-packages (from peft) (1.6.0)\n",
      "Requirement already satisfied: Mako in /venv/main/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.9)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /venv/main/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /venv/main/lib/python3.10/site-packages (from botocore<1.38.0,>=1.37.30->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /venv/main/lib/python3.10/site-packages (from botocore<1.38.0,>=1.37.30->boto3) (2.3.0)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /venv/main/lib/python3.10/site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /venv/main/lib/python3.10/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in /venv/main/lib/python3.10/site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /venv/main/lib/python3.10/site-packages (from aiohttp->datasets) (1.19.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /venv/main/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /venv/main/lib/python3.10/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /venv/main/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\n",
      "Requirement already satisfied: rich in /venv/main/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
      "Requirement already satisfied: namex in /venv/main/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /venv/main/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /venv/main/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /venv/main/lib/python3.10/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /venv/main/lib/python3.10/site-packages (from matplotlib<4->mlflow) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /venv/main/lib/python3.10/site-packages (from matplotlib<4->mlflow) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /venv/main/lib/python3.10/site-packages (from matplotlib<4->mlflow) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /venv/main/lib/python3.10/site-packages (from matplotlib<4->mlflow) (3.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /venv/main/lib/python3.10/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /venv/main/lib/python3.10/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /venv/main/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /venv/main/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /venv/main/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.21.3->mlflow) (2025.1.31)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /venv/main/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /venv/main/lib/python3.10/site-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
      "Requirement already satisfied: greenlet>=1 in /venv/main/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /venv/main/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: google-auth~=2.0 in /venv/main/lib/python3.10/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (2.38.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /venv/main/lib/python3.10/site-packages (from fastapi<1->mlflow-skinny==2.21.3->mlflow) (0.46.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /venv/main/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.21.3->mlflow) (4.0.12)\n",
      "Requirement already satisfied: zipp>=3.20 in /venv/main/lib/python3.10/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.21.3->mlflow) (3.21.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /venv/main/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow) (1.2.18)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b1 in /venv/main/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.21.3->mlflow) (0.52b1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /venv/main/lib/python3.10/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /venv/main/lib/python3.10/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /venv/main/lib/python3.10/site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.21.3->mlflow) (0.4.0)\n",
      "Requirement already satisfied: h11>=0.8 in /venv/main/lib/python3.10/site-packages (from uvicorn<1->mlflow-skinny==2.21.3->mlflow) (0.14.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /venv/main/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /venv/main/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /venv/main/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.21.3->mlflow) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /venv/main/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /venv/main/lib/python3.10/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (4.9)\n",
      "Requirement already satisfied: mdurl~=0.1 in /venv/main/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /venv/main/lib/python3.10/site-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.3->mlflow) (4.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /venv/main/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.3->mlflow) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /venv/main/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.21.3->mlflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /venv/main/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.21.3->mlflow) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip mlflow transformers datasets boto3 torch tensorflow huggingface_hub evaluate tqdm tf-keras peft \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install -U accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "iQ1uPCDxuV4D",
    "outputId": "4b7a7dde-be2f-4e18-a451-06a5ffe369a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 02:26:04.747528: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744165564.764707    3759 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744165564.770016    3759 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744165564.782417    3759 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744165564.782429    3759 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744165564.782431    3759 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744165564.782433    3759 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-09 02:26:04.786655: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    TextStreamer)\n",
    "\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import torch, gc, os\n",
    "import numpy as np\n",
    "# from unsloth.chat_templates import get_chat_template\n",
    "# from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.empty_cache()\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "59_cafVz7ys0"
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "ZsVxoK8Dudnf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b65f859366478d9dc77c5a41ff9e97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n",
    "# !huggingface-cli login --token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8-7sD2L-uV4E"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['description', 'transcription', 'sample_name', 'medical_specialty', 'keywords'],\n",
       "        num_rows: 1724\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['description', 'transcription', 'sample_name', 'medical_specialty', 'keywords'],\n",
       "        num_rows: 370\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['description', 'transcription', 'sample_name', 'medical_specialty', 'keywords'],\n",
       "        num_rows: 370\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"hpe-ai/medical-cases-classification-tutorial\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "F3NmPdLah94q"
   },
   "outputs": [],
   "source": [
    "# Columns to keep\n",
    "columns_to_keep = [\"transcription\", \"medical_specialty\"]\n",
    "\n",
    "# Remove all columns that are not in `columns_to_keep`\n",
    "dataset = dataset.remove_columns(\n",
    "    [col for col in dataset[\"train\"].column_names if col not in columns_to_keep]\n",
    ")\n",
    "\n",
    "dataset[\"validation\"] = dataset[\"validation\"].remove_columns(\n",
    "    [col for col in dataset[\"validation\"].column_names if col not in columns_to_keep]\n",
    ")\n",
    "\n",
    "dataset[\"test\"] = dataset[\"test\"].remove_columns(\n",
    "    [col for col in dataset[\"test\"].column_names if col not in columns_to_keep]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dSNj1sqJuV4E"
   },
   "outputs": [],
   "source": [
    "# dataset = dataset.remove_columns([col for col in dataset.column_names if col not in [\"transcription\", \"medical_specialty\"]])\n",
    "medical_test = dataset['test']\n",
    "medical_train = dataset['train']\n",
    "medical_val = dataset['validation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3HoqisM2uV4E"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PREOPERATIVE DIAGNOSIS:,  Dural tear, postoper...</td>\n",
       "      <td>Orthopedic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REASON FOR CONSULTATION: , Loculated left effu...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REASON FOR CONSULTATION:  ,Abnormal echocardio...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PREOPERATIVE DIAGNOSES: , Cervical spondylosis...</td>\n",
       "      <td>Orthopedic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC:, Weakness.,HX:, This 30 y/o RHM was in goo...</td>\n",
       "      <td>Neurology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       transcription  \\\n",
       "0  PREOPERATIVE DIAGNOSIS:,  Dural tear, postoper...   \n",
       "1  REASON FOR CONSULTATION: , Loculated left effu...   \n",
       "2  REASON FOR CONSULTATION:  ,Abnormal echocardio...   \n",
       "3  PREOPERATIVE DIAGNOSES: , Cervical spondylosis...   \n",
       "4  CC:, Weakness.,HX:, This 30 y/o RHM was in goo...   \n",
       "\n",
       "            medical_specialty  \n",
       "0                  Orthopedic  \n",
       "1  Cardiovascular / Pulmonary  \n",
       "2  Cardiovascular / Pulmonary  \n",
       "3                  Orthopedic  \n",
       "4                   Neurology  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = medical_test.to_pandas()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5NrfMu9wuV4E"
   },
   "outputs": [],
   "source": [
    "refined_train = train_df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "BCYCRI1gzY87"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medical_specialty\n",
       "Cardiovascular / Pulmonary    109\n",
       "Orthopedic                     57\n",
       "Neurology                      47\n",
       "Gastroenterology               41\n",
       "Obstetrics / Gynecology        32\n",
       "Neurosurgery                   20\n",
       "Hematology - Oncology          15\n",
       "ENT - Otolaryngology           14\n",
       "Ophthalmology                  11\n",
       "Nephrology                     10\n",
       "Psychiatry / Psychology         9\n",
       "Pediatrics - Neonatal           3\n",
       "Radiology                       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_train.medical_specialty.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tYv5-Q0zfB-"
   },
   "source": [
    "## Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "d6zJ7kZZvN5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline to test the model\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-1B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "WMpB8uK4wQ8-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'how are you? today we are going to see the new samsung galaxy tab 3 7.0, the tab'}]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "7Cf0g327znbv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label2id: {'Cardiovascular / Pulmonary': 0, 'Orthopedic': 1, 'Neurology': 2, 'Gastroenterology': 3, 'Obstetrics / Gynecology': 4, 'Neurosurgery': 5, 'Hematology - Oncology': 6, 'ENT - Otolaryngology': 7, 'Ophthalmology': 8, 'Nephrology': 9, 'Psychiatry / Psychology': 10, 'Pediatrics - Neonatal': 11, 'Radiology': 12}\n",
      "id2label: {0: 'Cardiovascular / Pulmonary', 1: 'Orthopedic', 2: 'Neurology', 3: 'Gastroenterology', 4: 'Obstetrics / Gynecology', 5: 'Neurosurgery', 6: 'Hematology - Oncology', 7: 'ENT - Otolaryngology', 8: 'Ophthalmology', 9: 'Nephrology', 10: 'Psychiatry / Psychology', 11: 'Pediatrics - Neonatal', 12: 'Radiology'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-3.2-1B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = 'meta-llama/Llama-3.2-1B'\n",
    "# Label Maps\n",
    "label2id = {\n",
    "    \"Cardiovascular / Pulmonary\": 0,\n",
    "    \"Orthopedic\": 1,\n",
    "    \"Neurology\": 2,\n",
    "    \"Gastroenterology\": 3,\n",
    "    \"Obstetrics / Gynecology\": 4,\n",
    "    \"Neurosurgery\": 5,\n",
    "    \"Hematology - Oncology\": 6,\n",
    "    \"ENT - Otolaryngology\": 7,\n",
    "    \"Ophthalmology\": 8,\n",
    "    \"Nephrology\": 9,\n",
    "    \"Psychiatry / Psychology\": 10,\n",
    "    \"Pediatrics - Neonatal\": 11,\n",
    "    \"Radiology\": 12\n",
    "}\n",
    "\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "print(\"label2id:\", label2id)\n",
    "print(\"id2label:\", id2label)\n",
    "\n",
    "\n",
    "# classification model from model_checkpoint\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, \n",
    "    num_labels=13, \n",
    "    id2label=id2label, \n",
    "    label2id=label2id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "gcaZEIw6wVUl"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)\n",
    "\n",
    "# add pad token if none exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': \"<pad>\"})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = model.config.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "pdKjNN1QqLi9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|end_of_text|>'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "r5erFCAi0lm2"
   },
   "outputs": [],
   "source": [
    "\n",
    "# create tokenize function\n",
    "def tokenize_function(data):\n",
    "    # extract text\n",
    "    text = data[\"transcription\"]\n",
    "    label = [label2id[val] for val in data[\"medical_specialty\"]]\n",
    "\n",
    "    #tokenize and truncate text\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "    tokenized_inputs[\"labels\"] = label\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "SdnoRgLt0w_J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['transcription', 'medical_specialty', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1724\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['transcription', 'medical_specialty', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 370\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['transcription', 'medical_specialty', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 370\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "v0nFQXZw01jA"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egZj1xD04CKn"
   },
   "source": [
    "## Check for Accuracy for current dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "9gvRt5U23lO_"
   },
   "outputs": [],
   "source": [
    "accuracy_metrics = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "rD1FQ49w4LPo"
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(preds):\n",
    "    predictions, labels  = preds\n",
    "    return f\"Accuracy is {accuracy_metrics.compute(predictions=predictions, references= labels)}\"\n",
    "\n",
    "def get_metrics(preds):\n",
    "    logits, labels = preds\n",
    "    predictions = torch.argmax(torch.tensor(logits), dim=1)\n",
    "\n",
    "    return accuracy_metrics.compute(\n",
    "        predictions=predictions.tolist(),\n",
    "        references=labels.tolist()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "ymcA4fum45XY"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_specialty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PREOPERATIVE DIAGNOSIS:,  Dural tear, postoper...</td>\n",
       "      <td>Orthopedic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REASON FOR CONSULTATION: , Loculated left effu...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REASON FOR CONSULTATION:  ,Abnormal echocardio...</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PREOPERATIVE DIAGNOSES: , Cervical spondylosis...</td>\n",
       "      <td>Orthopedic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC:, Weakness.,HX:, This 30 y/o RHM was in goo...</td>\n",
       "      <td>Neurology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       transcription  \\\n",
       "0  PREOPERATIVE DIAGNOSIS:,  Dural tear, postoper...   \n",
       "1  REASON FOR CONSULTATION: , Loculated left effu...   \n",
       "2  REASON FOR CONSULTATION:  ,Abnormal echocardio...   \n",
       "3  PREOPERATIVE DIAGNOSES: , Cervical spondylosis...   \n",
       "4  CC:, Weakness.,HX:, This 30 y/o RHM was in goo...   \n",
       "\n",
       "            medical_specialty  \n",
       "0                  Orthopedic  \n",
       "1  Cardiovascular / Pulmonary  \n",
       "2  Cardiovascular / Pulmonary  \n",
       "3                  Orthopedic  \n",
       "4                   Neurology  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = medical_test.to_pandas()[columns_to_keep]\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "drF0sGK84-f0"
   },
   "outputs": [],
   "source": [
    "def call_model(rows, model=model):\n",
    "  text = rows['transcription']\n",
    "  inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "  inputs = inputs.to(model.device)\n",
    "\n",
    "  #Compute Logits\n",
    "  logits = model(inputs).logits\n",
    "\n",
    "  #Convert logits to label\n",
    "  predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "  return id2label[predictions.item()]\n",
    "\n",
    "# test_df['Base_Model_Output'] = test_df.progress_apply(call_model, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "CI6OOJwr5f4l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is {'accuracy': 0.002702702702702703}\n"
     ]
    }
   ],
   "source": [
    "test_df['Base_Model_Output_Id'] = test_df['Base_Model_Output'].apply(lambda x: label2id[x])\n",
    "test_df['medical_specialty_id'] = test_df['medical_specialty'].apply(lambda x: label2id[x])\n",
    "# import pandas as pd\n",
    "# test_df = pd.read_csv('base_model_output.csv')\n",
    "print(calculate_metrics((test_df['Base_Model_Output_Id'].tolist(), test_df['medical_specialty_id'].tolist())))\n",
    "\n",
    "test_df.to_csv('base_model_output.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-R-IQxB7I-QB"
   },
   "source": [
    "Since we are not getting good accuracies on the base model, let's try to fine tune the model, but use Parameter Efficient Fine Tuning (PEfT) using Low Rank Apadtation Matrices (LoRA), so as to avoid bigger model size, or catastrophic forgetting, we'll have lower parameters to train the model on, with it's original weights intact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HToIEJsYJaHD"
   },
   "source": [
    "## Model Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "ULktTJeGGsWx"
   },
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\", # Using for Sequence Classification\n",
    "                        r=4, # keeping the rank small because of faster training\n",
    "                        lora_alpha=32, # Keeping it 32 for efficient Training\n",
    "                        lora_dropout=0.05, # Making sure it doesn't overfit\n",
    "                        use_rslora=True, # For efficient Training, Helps with convergence\n",
    "                        target_modules = ['q_lin', 'v_proj'])  # Good performance/cost trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "7e7ys1EQMi1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 190,464 || all params: 1,236,033,536 || trainable%: 0.0154\n"
     ]
    }
   ],
   "source": [
    "peft_model = get_peft_model(model, peft_config)\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "2jG7Vy5JQ7al"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /root/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['accelerate', 'config', 'default'], returncode=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "subprocess.run([\"accelerate\", \"config\", \"default\"], input=b\"\\n\".join([\n",
    "    b\"0\",       # This machine\n",
    "    b\"1\",       # Multi-GPU\n",
    "    b\"8\",       # Number of processes (GPUs)\n",
    "    b\"no\",      # Use DeepSpeed: no\n",
    "]), check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "lYbxeda0MnAr"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 4\n",
    "num_epochs = 10\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoint\",\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    gradient_accumulation_steps=4,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    eval_accumulation_steps = 1,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=2,\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "-JGZOTGzPkUL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3759/3879297496.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n",
    "    compute_metrics=get_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Ey3dlNKZTAgC"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1070' max='1070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1070/1070 08:02, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.129500</td>\n",
       "      <td>1.379465</td>\n",
       "      <td>0.727027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.094700</td>\n",
       "      <td>0.867492</td>\n",
       "      <td>0.775676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.776600</td>\n",
       "      <td>0.726977</td>\n",
       "      <td>0.789189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.641700</td>\n",
       "      <td>0.636631</td>\n",
       "      <td>0.797297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.525600</td>\n",
       "      <td>0.704872</td>\n",
       "      <td>0.808108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.462100</td>\n",
       "      <td>0.862990</td>\n",
       "      <td>0.802703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.393300</td>\n",
       "      <td>0.791373</td>\n",
       "      <td>0.816216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.336800</td>\n",
       "      <td>0.785252</td>\n",
       "      <td>0.791892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.240200</td>\n",
       "      <td>0.949894</td>\n",
       "      <td>0.783784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.10/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/venv/main/lib/python3.10/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/venv/main/lib/python3.10/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/venv/main/lib/python3.10/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/venv/main/lib/python3.10/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/venv/main/lib/python3.10/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/venv/main/lib/python3.10/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/venv/main/lib/python3.10/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/venv/main/lib/python3.10/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/venv/main/lib/python3.10/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1070, training_loss=0.6567519562266697, metrics={'train_runtime': 482.188, 'train_samples_per_second': 35.754, 'train_steps_per_second': 2.219, 'total_flos': 5.10840941838336e+16, 'train_loss': 0.6567519562266697, 'epoch': 9.909512761020881})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As we can see, the validation loss started increasing even after applying L2 regularization and Dropout layer. This means the model started to overfit after epoch 5. We further need to apply early stopping and decrease the dropour layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# EarlyStoppingCallback to stop training if validation loss does not improve\n",
    "early_stopping = EarlyStoppingCallback(\n",
    "    early_stopping_patience=2,  # Wait for 2 epochs of no improvement\n",
    "    early_stopping_threshold=0.01  # The minimum improvement required is 0.01\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 190,464 || all params: 1,236,033,536 || trainable%: 0.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.10/site-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/venv/main/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "peft_config_v2 = LoraConfig(task_type=\"SEQ_CLS\", # Using for Sequence Classification\n",
    "                        r=4, # keeping the rank small because of faster training\n",
    "                        lora_alpha=32, # Keeping it 32 for efficient Training\n",
    "                        lora_dropout=0.01, # Making sure it doesn't overfit\n",
    "                        use_rslora=True, # For efficient Training, Helps with convergence\n",
    "                        target_modules = ['q_lin', 'v_proj'])  # Good performance/cost trade-off\n",
    "peft_model_v2 = get_peft_model(model, peft_config_v2)\n",
    "peft_model_v2.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3759/1309950691.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 4\n",
    "num_epochs = 10\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoint\",\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    gradient_accumulation_steps=4,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",  # Metric to monitor for early stopping\n",
    "    eval_accumulation_steps = 1,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=2,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model_v2,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator, # this will dynamically pad examples in each batch to be equal length\n",
    "    compute_metrics=get_metrics,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='432' max='1070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 432/1070 03:14 < 04:48, 2.21 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.221300</td>\n",
       "      <td>1.465908</td>\n",
       "      <td>0.659459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.868900</td>\n",
       "      <td>0.798287</td>\n",
       "      <td>0.770270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.636200</td>\n",
       "      <td>0.851329</td>\n",
       "      <td>0.737838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.506600</td>\n",
       "      <td>0.844056</td>\n",
       "      <td>0.767568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.10/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/venv/main/lib/python3.10/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/venv/main/lib/python3.10/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "/venv/main/lib/python3.10/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=432, training_loss=0.7900345325469971, metrics={'train_runtime': 193.9036, 'train_samples_per_second': 88.91, 'train_steps_per_second': 5.518, 'total_flos': 2.06202243907584e+16, 'train_loss': 0.7900345325469971, 'epoch': 4.0})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing PEFT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 370/370 [00:10<00:00, 34.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is {'accuracy': 0.7648648648648648}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# peft_model_v2\n",
    "test_df['Fine_Tuned_Model_Output'] = test_df.progress_apply((lambda row: call_model(row, peft_model_v2)), axis=1)\n",
    "test_df['Fine_Tuned_Model_Output_Id'] = test_df['Fine_Tuned_Model_Output'].apply(lambda x: label2id[x])\n",
    "# test_df['medical_specialty_id'] = test_df['medical_specialty'].apply(lambda x: label2id[x])\n",
    "# import pandas as pd\n",
    "# test_df = pd.read_csv('base_model_output.csv')\n",
    "print(calculate_metrics((test_df['Fine_Tuned_Model_Output_Id'].tolist(), test_df['medical_specialty_id'].tolist())))\n",
    "\n",
    "test_df.to_csv('Fine_Tuned_model_output.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Model's Accuracy was {'accuracy': 0.27%} \n",
    "\n",
    "Fine Tuned Model's Accuracy is {'accuracy': 76.4%}\n",
    "\n",
    "After Fine Tuning the model, we have increased the accuracies by ~76.2%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pushing the model to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama-3.2-1B'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint.split(\"/\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/venv/main/lib/python3.10/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b44d23b545246e390e0ae2a1cde95dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/1.05G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/adityatandon94/Llama-3.2-1B-peft-medical-specialty-classification/commit/8d30d7df88293c1c9e18cca2c6c0b6ba31e6947c', commit_message='Upload model', commit_description='', oid='8d30d7df88293c1c9e18cca2c6c0b6ba31e6947c', pr_url=None, repo_url=RepoUrl('https://huggingface.co/adityatandon94/Llama-3.2-1B-peft-medical-specialty-classification', endpoint='https://huggingface.co', repo_type='model', repo_id='adityatandon94/Llama-3.2-1B-peft-medical-specialty-classification'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_name = 'adityatandon94' \n",
    "model_id = hf_name + \"/\" + model_checkpoint.split(\"/\")[1] + \"-peft-medical-specialty-classification\" \n",
    "peft_model_v2.push_to_hub(model_id) # save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667cc7e82862477b8d9b6652ec890c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f73295893694eda882c22f27907df82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/1.05G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49856aa02c3f4512992c91d2a0c35ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32dd7b79f454af0a502fea8797628c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/adityatandon94/checkpoint/commit/a7baef521e6bcaa7ee8af65aa6d6c9202cc6d8d0', commit_message='adityatandon94/Llama-3.2-1B-peft-medical-specialty-classification', commit_description='', oid='a7baef521e6bcaa7ee8af65aa6d6c9202cc6d8d0', pr_url=None, repo_url=RepoUrl('https://huggingface.co/adityatandon94/checkpoint', endpoint='https://huggingface.co', repo_type='model', repo_id='adityatandon94/checkpoint'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Kill Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "yrO6V3YfndGu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr  9 02:09:46 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.58.02              Driver Version: 555.58.02      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        On  |   00000000:01:00.0 Off |                  Off |\n",
      "|  0%   34C    P8             13W /  385W |   12706MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        On  |   00000000:83:00.0 Off |                  Off |\n",
      "|  0%   37C    P8             22W /  385W |   24076MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   2  NVIDIA GeForce RTX 4090        On  |   00000000:84:00.0 Off |                  Off |\n",
      "|  0%   40C    P8             19W /  385W |   24076MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   3  NVIDIA GeForce RTX 4090        On  |   00000000:85:00.0 Off |                  Off |\n",
      "|  0%   42C    P8             19W /  385W |   24076MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   4  NVIDIA GeForce RTX 4090        On  |   00000000:86:00.0 Off |                  Off |\n",
      "|  0%   40C    P8             17W /  385W |   24076MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   5  NVIDIA GeForce RTX 4090        On  |   00000000:87:00.0 Off |                  Off |\n",
      "|  0%   37C    P8             20W /  385W |   24076MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   6  NVIDIA GeForce RTX 4090        On  |   00000000:89:00.0 Off |                  Off |\n",
      "|  0%   43C    P8              6W /  385W |   24076MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   7  NVIDIA GeForce RTX 4090        On  |   00000000:C1:00.0 Off |                  Off |\n",
      "|  0%   43C    P8             29W /  385W |   24076MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   8  NVIDIA GeForce RTX 4090        On  |   00000000:C2:00.0 Off |                  Off |\n",
      "|  0%   42C    P8             19W /  385W |   24076MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "# !kill -9 1659\n",
    "# # !ps aux | grep python\n",
    "# # !pkill -f python\n",
    "# !kill -9 $(nvidia-smi | grep python | awk '{print $5}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "qxsWR6jOM3P3"
   },
   "outputs": [],
   "source": [
    "# trainer.train(resume_from_checkpoint=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "3.9.17",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
